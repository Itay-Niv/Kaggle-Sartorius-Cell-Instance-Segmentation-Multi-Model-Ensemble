{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19602,"status":"ok","timestamp":1646507445659,"user":{"displayName":"Itay Niv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghjhfk_XC7CoEG1g-HRSDlb9oumYa_3KslRq2VzHPY=s64","userId":"06492658618467845922"},"user_tz":-120},"id":"6ZE40E71hdsU","outputId":"df59a98e-cf50-44d4-e07c-93a514943854"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["# Mounting Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1646507445660,"user":{"displayName":"Itay Niv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghjhfk_XC7CoEG1g-HRSDlb9oumYa_3KslRq2VzHPY=s64","userId":"06492658618467845922"},"user_tz":-120},"id":"4zu6o2HGHkGn"},"outputs":[],"source":["# Specify YOUR working directory:\n","main_dir = \"/content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/\" #'YOUR_MAIN_DIR'"]},{"cell_type":"markdown","metadata":{"id":"Do-Z8Hz-HlI5"},"source":["# Setup:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1646507445661,"user":{"displayName":"Itay Niv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghjhfk_XC7CoEG1g-HRSDlb9oumYa_3KslRq2VzHPY=s64","userId":"06492658618467845922"},"user_tz":-120},"id":"azEYbrSePFDv","outputId":"89134d66-39c5-467e-ca6c-4909be1e15b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Mar  5 19:10:45 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1646507445661,"user":{"displayName":"Itay Niv","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghjhfk_XC7CoEG1g-HRSDlb9oumYa_3KslRq2VzHPY=s64","userId":"06492658618467845922"},"user_tz":-120},"id":"MSbZARCh6Kv3","outputId":"1305a904-3827-44dd-baa6-83174d6eda0b"},"outputs":[{"output_type":"display_data","data":{"application/javascript":["function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}],"source":["%%javascript\n","function ClickConnect(){\n","console.log(\"Working\");\n","document.querySelector(\"colab-toolbar-button#connect\").click()\n","}setInterval(ClickConnect,60000)"]},{"cell_type":"markdown","metadata":{"id":"UE-b_ytghMlX"},"source":["# Installing Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLDy9cCqHwlF","outputId":"387b33c5-946d-458a-cb35-57329a8724aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./install/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","Successfully installed torch-1.7.1+cu110\n","Processing ./install/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl\n","Installing collected packages: torchvision\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","Successfully installed torchvision-0.8.2+cu110\n","Processing ./install/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl\n","Installing collected packages: torchaudio\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed torchaudio-0.7.2\n","Processing ./install/addict-2.4.0-py3-none-any.whl\n","Installing collected packages: addict\n","Successfully installed addict-2.4.0\n","Processing ./install/yapf-0.31.0-py2.py3-none-any.whl\n","Installing collected packages: yapf\n","Successfully installed yapf-0.31.0\n","Processing ./install/terminal-0.4.0-py3-none-any.whl\n","Installing collected packages: terminal\n","Successfully installed terminal-0.4.0\n","Processing ./install/terminaltables-3.1.0-py3-none-any.whl\n","Installing collected packages: terminaltables\n","Successfully installed terminaltables-3.1.0\n","Processing ./install/mmcv_full-1.3.17-cp37-cp37m-manylinux1_x86_64.whl\n","Installing collected packages: mmcv-full\n","Successfully installed mmcv-full-1.3.17\n","Processing ./install/pycocotools-2.0.2\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=264382 sha256=beafd3b5de9ec916cd805ed110486226d283a77dc8c1bffedc705cbc799390bb\n","  Stored in directory: /root/.cache/pip/wheels/a4/78/70/b949bc8606a1aaa9825ffe2da3eaadd3f73fa006af201c4e1d\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.4\n","    Uninstalling pycocotools-2.0.4:\n","      Successfully uninstalled pycocotools-2.0.4\n","Successfully installed pycocotools-2.0.2\n","Processing ./install/mmpycocotools-12.0.3\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Building wheels for collected packages: mmpycocotools\n","  Building wheel for mmpycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmpycocotools: filename=mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl size=264672 sha256=b720756311d3591c2abe31fa7886230d758599c0199c5000a98138d9f476594c\n","  Stored in directory: /root/.cache/pip/wheels/ac/94/9d/2cf7b8436319fe75a9e070d5a4e93ba8f056d3e261ceec1302\n","Successfully built mmpycocotools\n","Installing collected packages: mmpycocotools\n","Successfully installed mmpycocotools-12.0.3\n","Collecting ensemble-boxes\n","  Downloading ensemble_boxes-1.0.8-py3-none-any.whl (21 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (1.21.5)\n","Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from ensemble-boxes) (0.51.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->ensemble-boxes) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->ensemble-boxes) (0.34.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ensemble-boxes) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ensemble-boxes) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ensemble-boxes) (1.15.0)\n","Installing collected packages: ensemble-boxes\n","Successfully installed ensemble-boxes-1.0.8\n","fatal: destination path 'mmsegmentation' already exists and is not an empty directory.\n","/content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/mmsegmentation\n","Obtaining file:///content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/mmsegmentation\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.21.1) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.21.1) (1.21.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.21.1) (21.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.21.1) (3.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.21.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.21.1) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.21.1) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.21.1) (3.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.21.1) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.21.1) (4.11.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.21.1) (0.2.5)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.21.1) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.21.1) (3.7.0)\n","Installing collected packages: mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmsegmentation-0.21.1\n","/content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/mmdetection-2.18.0\n","Obtaining file:///content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/mmdetection-2.18.0\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.0) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.0) (1.21.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.0) (1.15.0)\n","Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.0) (3.1.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.18.0) (2.0.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.0) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.0) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.0) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.18.0) (3.0.7)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.0) (0.29.28)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->mmdet==2.18.0) (57.4.0)\n","Installing collected packages: mmdet\n","  Running setup.py develop for mmdet\n","Successfully installed mmdet-2.18.0\n","Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Collecting imgaug>=0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 58.2 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=56d7cbdaa8cafadc80407f9a45eaae71dcb44f805eb13373931f8bf10663383b\n","  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n","Successfully built albumentations\n","Installing collected packages: imgaug, albumentations\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.4.6 imgaug-0.4.0\n","fatal: destination path 'SoftTeacher' already exists and is not an empty directory.\n","/content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/SoftTeacher\n","running develop\n","running egg_info\n","writing ssod.egg-info/PKG-INFO\n","writing dependency_links to ssod.egg-info/dependency_links.txt\n","writing requirements to ssod.egg-info/requires.txt\n","writing top-level names to ssod.egg-info/top_level.txt\n","adding license file 'LICENSE'\n","writing manifest file 'ssod.egg-info/SOURCES.txt'\n","running build_ext\n","Creating /usr/local/lib/python3.7/dist-packages/ssod.egg-link (link to .)\n","Adding ssod 0.0.1 to easy-install.pth file\n","\n","Installed /content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/GIT/install/SoftTeacher\n","Processing dependencies for ssod==0.0.1\n","Searching for wandb\n","Reading https://pypi.org/simple/wandb/\n","Downloading https://files.pythonhosted.org/packages/e6/1e/6ae3c7774b6537a48a1a896b483fcd13b09d7ca3ace63f423f6cff828b56/wandb-0.12.11-py2.py3-none-any.whl#sha256=3a8637ae1b580d5839bde4792d9c31ecd40392ae8a245874391edd82c74e7b17\n","Best match: wandb 0.12.11\n","Processing wandb-0.12.11-py2.py3-none-any.whl\n","Installing wandb-0.12.11-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding wandb 0.12.11 to easy-install.pth file\n","Installing wandb script to /usr/local/bin\n","Installing wb script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.7/dist-packages/wandb-0.12.11-py3.7.egg\n","Searching for yaspin>=1.0.0\n","Reading https://pypi.org/simple/yaspin/\n","Downloading https://files.pythonhosted.org/packages/ce/ed/1ae83648729025952b483046d5164fc91625703899707655406db76ce671/yaspin-2.1.0-py3-none-any.whl#sha256=d574cbfaf0a349df466c91f7f81b22460ae5ebb15ecb8bf9411d6049923aee8d\n","Best match: yaspin 2.1.0\n","Processing yaspin-2.1.0-py3-none-any.whl\n","Installing yaspin-2.1.0-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding yaspin 2.1.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/yaspin-2.1.0-py3.7.egg\n","Searching for shortuuid>=0.5.0\n","Reading https://pypi.org/simple/shortuuid/\n","Downloading https://files.pythonhosted.org/packages/22/1b/dda73524fc8dd5cd3b80adcc585a49b3f43f8889453d2ed96291b2fcc860/shortuuid-1.0.8-py3-none-any.whl#sha256=44a7a86bcf24dbaba2e626cf80c779926b7c3a0d31a3a013e0d3cd1077707d23\n","Best match: shortuuid 1.0.8\n","Processing shortuuid-1.0.8-py3-none-any.whl\n","Installing shortuuid-1.0.8-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding shortuuid 1.0.8 to easy-install.pth file\n","Installing shortuuid script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.7/dist-packages/shortuuid-1.0.8-py3.7.egg\n","Searching for setproctitle\n","Reading https://pypi.org/simple/setproctitle/\n","Downloading https://files.pythonhosted.org/packages/97/5c/16a6e69febfbee3f1a1a8c4318d1f054ff4d3ef2a61b233937c316cba06d/setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl#sha256=e696c93d93c23f377ccd2d72e38908d3dbfc90e45561602b805f53f2627d42ea\n","Best match: setproctitle 1.2.2\n","Processing setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl\n","Installing setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n","Adding setproctitle 1.2.2 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/setproctitle-1.2.2-py3.7-linux-x86_64.egg\n","Searching for sentry-sdk>=1.0.0\n","Reading https://pypi.org/simple/sentry-sdk/\n","Downloading https://files.pythonhosted.org/packages/a5/7f/af0b6378d3d536705ab1df290563919ff3da314b0cdf2587bc7a66caceb1/sentry_sdk-1.5.6-py2.py3-none-any.whl#sha256=1ab34e3851a34aeb3d1af1a0f77cec73978c4e9698e5210d050e4932953cb241\n","Best match: sentry-sdk 1.5.6\n","Processing sentry_sdk-1.5.6-py2.py3-none-any.whl\n","Installing sentry_sdk-1.5.6-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding sentry-sdk 1.5.6 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/sentry_sdk-1.5.6-py3.7.egg\n","Searching for pathtools\n","Reading https://pypi.org/simple/pathtools/\n","Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz#sha256=7c35c5421a39bb82e58018febd90e3b6e5db34c5443aaaf742b3f33d4655f1c0\n","Best match: pathtools 0.1.2\n","Processing pathtools-0.1.2.tar.gz\n","Writing /tmp/easy_install-g4vh3x8o/pathtools-0.1.2/setup.cfg\n","Running pathtools-0.1.2/setup.py -q bdist_egg --dist-dir /tmp/easy_install-g4vh3x8o/pathtools-0.1.2/egg-dist-tmp-qn0si6j1\n","/tmp/easy_install-g4vh3x8o/pathtools-0.1.2/setup.py:25: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n","  import imp\n","zip_safe flag not set; analyzing archive contents...\n","Moving pathtools-0.1.2-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding pathtools 0.1.2 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/pathtools-0.1.2-py3.7.egg\n","Searching for docker-pycreds>=0.4.0\n","Reading https://pypi.org/simple/docker-pycreds/\n","Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl#sha256=7266112468627868005106ec19cd0d722702d2b7d5912a28e19b826c3d37af49\n","Best match: docker-pycreds 0.4.0\n","Processing docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Installing docker_pycreds-0.4.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding docker-pycreds 0.4.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/docker_pycreds-0.4.0-py3.7.egg\n","Searching for GitPython>=1.0.0\n","Reading https://pypi.org/simple/GitPython/\n","Downloading https://files.pythonhosted.org/packages/83/32/ce68915670da6fd6b1e3fb4b3554b4462512f6441dddd194fc0f4f6ec653/GitPython-3.1.27-py3-none-any.whl#sha256=5b68b000463593e05ff2b261acff0ff0972df8ab1b70d3cdbd41b546c8b8fc3d\n","Best match: GitPython 3.1.27\n","Processing GitPython-3.1.27-py3-none-any.whl\n","Installing GitPython-3.1.27-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding GitPython 3.1.27 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/GitPython-3.1.27-py3.7.egg\n","Searching for gitdb<5,>=4.0.1\n","Reading https://pypi.org/simple/gitdb/\n","Downloading https://files.pythonhosted.org/packages/a3/7c/5d747655049bfbf75b5fcec57c8115896cb78d6fafa84f6d3ef4c0f13a98/gitdb-4.0.9-py3-none-any.whl#sha256=8033ad4e853066ba6ca92050b9df2f89301b8fc8bf7e9324d412a63f8bf1a8fd\n","Best match: gitdb 4.0.9\n","Processing gitdb-4.0.9-py3-none-any.whl\n","Installing gitdb-4.0.9-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding gitdb 4.0.9 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/gitdb-4.0.9-py3.7.egg\n","Searching for smmap<6,>=3.0.1\n","Reading https://pypi.org/simple/smmap/\n","Downloading https://files.pythonhosted.org/packages/6d/01/7caa71608bc29952ae09b0be63a539e50d2484bc37747797a66a60679856/smmap-5.0.0-py3-none-any.whl#sha256=2aba19d6a040e78d8b09de5c57e96207b09ed71d8e55ce0959eeee6c8e190d94\n","Best match: smmap 5.0.0\n","Processing smmap-5.0.0-py3-none-any.whl\n","Installing smmap-5.0.0-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding smmap 5.0.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/smmap-5.0.0-py3.7.egg\n","Searching for prettytable==3.1.1\n","Best match: prettytable 3.1.1\n","Adding prettytable 3.1.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for mmcv-full==1.3.17\n","Best match: mmcv-full 1.3.17\n","Adding mmcv-full 1.3.17 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for torchvision==0.8.2+cu110\n","Best match: torchvision 0.8.2+cu110\n","Adding torchvision 0.8.2+cu110 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for torch==1.7.1+cu110\n","Best match: torch 1.7.1+cu110\n","Adding torch 1.7.1+cu110 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for wcwidth==0.2.5\n","Best match: wcwidth 0.2.5\n","Adding wcwidth 0.2.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for importlib-metadata==4.11.2\n","Best match: importlib-metadata 4.11.2\n","Adding importlib-metadata 4.11.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for requests==2.23.0\n","Best match: requests 2.23.0\n","Adding requests 2.23.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for python-dateutil==2.8.2\n","Best match: python-dateutil 2.8.2\n","Adding python-dateutil 2.8.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for psutil==5.4.8\n","Best match: psutil 5.4.8\n","Adding psutil 5.4.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for protobuf==3.17.3\n","Best match: protobuf 3.17.3\n","Adding protobuf 3.17.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for promise==2.3\n","Best match: promise 2.3\n","Adding promise 2.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for PyYAML==3.13\n","Best match: PyYAML 3.13\n","Adding PyYAML 3.13 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for click==7.1.2\n","Best match: click 7.1.2\n","Adding click 7.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for packaging==21.3\n","Best match: packaging 21.3\n","Adding packaging 21.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for yapf==0.31.0\n","Best match: yapf 0.31.0\n","Adding yapf 0.31.0 to easy-install.pth file\n","Installing yapf script to /usr/local/bin\n","Installing yapf-diff script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for addict==2.4.0\n","Best match: addict 2.4.0\n","Adding addict 2.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Pillow==7.1.2\n","Best match: Pillow 7.1.2\n","Adding Pillow 7.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for opencv-python==4.1.2.30\n","Best match: opencv-python 4.1.2.30\n","Adding opencv-python 4.1.2.30 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for numpy==1.21.5\n","Best match: numpy 1.21.5\n","Adding numpy 1.21.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.7 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for typing-extensions==3.10.0.2\n","Best match: typing-extensions 3.10.0.2\n","Adding typing-extensions 3.10.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for zipp==3.7.0\n","Best match: zipp 3.7.0\n","Adding zipp 3.7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for termcolor==1.1.0\n","Best match: termcolor 1.1.0\n","Adding termcolor 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for certifi==2021.10.8\n","Best match: certifi 2021.10.8\n","Adding certifi 2021.10.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for chardet==3.0.4\n","Best match: chardet 3.0.4\n","Adding chardet 3.0.4 to easy-install.pth file\n","Installing chardetect script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for idna==2.10\n","Best match: idna 2.10\n","Adding idna 2.10 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pyparsing==3.0.7\n","Best match: pyparsing 3.0.7\n","Adding pyparsing 3.0.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Finished processing dependencies for ssod==0.0.1\n"]}],"source":["import os\n","os.chdir(main_dir)\n","\n","!pip install './install/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n","!pip install './install/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n","!pip install './install/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n","\n","!pip install './install/addict-2.4.0-py3-none-any.whl' --no-deps\n","!pip install './install/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n","!pip install './install/terminal-0.4.0-py3-none-any.whl' --no-deps\n","!pip install './install/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n","!pip install './install/mmcv_full-1.3.17-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n","!pip install './install/pycocotools-2.0.2' --no-deps\n","!pip install './install/mmpycocotools-12.0.3' --no-deps\n","\n","!pip install ensemble-boxes\n","\n","os.chdir(main_dir + '/install/')\n","!git clone https://github.com/open-mmlab/mmsegmentation.git \n","%cd mmsegmentation\n","!pip install -e .\n","import mmseg\n","\n","\n","os.chdir(main_dir)\n","%cd ./install/mmdetection-2.18.0\n","!pip install -e .\n","import mmdet\n","\n","!pip install albumentations==0.4.6\n","\n","os.chdir(main_dir + '/install/')\n","!git clone https://github.com/microsoft/SoftTeacher/\n","%cd SoftTeacher\n","!python setup.py develop\n","from ssod.utils import patch_config\n","%cd -\n","\n","os.chdir(main_dir)\n","\n","import sys\n","sys.path.insert(1,main_dir + '/install/content/SoftTeacher')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vF2konKjyAcq"},"outputs":[],"source":["import torch\n","print(torch.__version__)\n","print(\"mmcv_full:\")\n","!pip show mmcv_full |grep Version\n","print(\"mmdet:\")\n","!pip show mmdet |grep Version\n","print(\"mmseg:\")\n","print(mmseg.__version__)"]},{"cell_type":"markdown","metadata":{"id":"N6htw1mJa7sc"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hyn5kN1a-y4"},"outputs":[],"source":["import sys\n","import os\n","import numpy as np\n","# Soft Teacher\n","import argparse\n","import os.path as osp\n","import time\n","import warnings\n","\n","import mmcv\n","import torch\n","from mmcv import Config, DictAction\n","from mmcv.cnn import fuse_conv_bn\n","from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n","from mmcv.runner import get_dist_info, init_dist, load_checkpoint, wrap_fp16_model\n","from mmdet.apis import multi_gpu_test, single_gpu_test\n","from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n","from mmdet.models import build_detector\n","from mmdet.core.visualization import imshow_det_bboxes\n","\n","from ssod.utils import patch_config\n","\n","# WBF\n","import pickle\n","import json\n","from ensemble_boxes import *\n","\n","# SEG\n","sys.path.append(main_dir + '/install/')\n","import seg_swin_cell_modules\n","import cv2\n","cv2.setNumThreads(0)\n","\n","import argparse\n","import os.path as osp\n","import shutil\n","import time\n","from mmcv.utils import DictAction\n","from mmseg.apis import multi_gpu_test, single_gpu_test\n","from mmseg.datasets import build_dataloader, build_dataset\n","from mmseg.models import build_segmentor"]},{"cell_type":"markdown","metadata":{"id":"477djPb4cWNW"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LOZxeE4ubYH0"},"outputs":[],"source":["def wbf_si(bbox_models,img_scale,weights,iou_thr,skip_box_thr):\n","    num_of_models = 0\n","    if any(isinstance(i, list) for i in bbox_models[0]):\n","        num_of_models = len(bbox_models)\n","        num_of_imgs = len(bbox_models[0])\n","        num_of_classes = len(bbox_models[0][0])\n","        res = [[]] * num_of_imgs\n","    else:\n","        num_of_models = 1\n","        num_of_imgs = len(bbox_models)\n","        num_of_classes = len(bbox_models[0])\n","        res = [[]] * num_of_imgs\n","    HIEGHT = img_scale[0]\n","    WIDTH = img_scale[1]\n","    for i in range(num_of_imgs):\n","        res[i] = [[]] * num_of_classes\n","        for j in range(num_of_classes):\n","            boxes_list = []\n","            scores_list = []\n","            labels_list = []\n","            for m in range(num_of_models):\n","                if num_of_models > 1:\n","                    instance_array = bbox_models[m][i][j]\n","                    num_of_instances = np.size(instance_array,0)\n","                elif num_of_models == 1:\n","                    instance_array = bbox_models[i][j]\n","                    num_of_instances = np.size(instance_array, 0)\n","                bbox = []\n","                score = []\n","                lbl = [j] * num_of_instances\n","                for k in range(num_of_instances):\n","                    bbox.append([instance_array[k][0] / WIDTH, instance_array[k][1] / HIEGHT,\n","                                  instance_array[k][2] / WIDTH,\n","                                  instance_array[k][3] / HIEGHT])\n","                    score.append(instance_array[k][-1])\n","                boxes_list.append(bbox)\n","                scores_list.append(score)\n","                labels_list.append(lbl)\n","\n","            if num_of_instances > 0:\n","                boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=weights,\n","                                                          iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n","            else:\n","                boxes, scores, labels = [[]] * 3\n","\n","            bbox_array = np.zeros(shape=(len(scores),5), dtype=np.float32)\n","            for m in range(len(boxes)):\n","                bbox_array[m,:] = [boxes[m][0] * WIDTH, boxes[m][1] * HIEGHT, boxes[m][2] * WIDTH, boxes[m][3] * HIEGHT, scores[m]]\n","            res[i][j]=bbox_array\n","    return res\n","\n","\n","def pkl_labels_fuc(pkl, j):\n","    class0_n=len(pkl[j][0])\n","    class1_n=len(pkl[j][1])\n","    class2_n=len(pkl[j][2])\n","    pkl_labels=[]\n","    for i in range(class0_n):\n","        pkl_labels.append(0)\n","    for i in range(class1_n):\n","        pkl_labels.append(1)\n","    for i in range(class2_n):\n","        pkl_labels.append(2)\n","    \n","    return np.asarray(pkl_labels)\n","\n","def evaluate_and_show(dataset,\n","                      results,\n","                      topk=20,\n","                      show_dir='work_dir',\n","                      eval_fn=None):\n","                      #self\n","    \"\"\"Evaluate and show results.\n","    Args:\n","        dataset (Dataset): A PyTorch dataset.\n","        results (list): Det results from test results pkl file\n","        topk (int): Number of the highest topk and\n","            lowest topk after evaluation index sorting. Default: 20\n","        show_dir (str, optional): The filename to write the image.\n","            Default: 'work_dir'\n","        eval_fn (callable, optional): Eval function, Default: None\n","    \"\"\"\n","\n","    assert topk > 0\n","    if (topk * 2) > len(dataset):\n","        topk = len(dataset) // 2\n","\n","    if eval_fn is None:\n","        eval_fn = bbox_map_eval\n","    else:\n","        assert callable(eval_fn)\n","\n","    prog_bar = mmcv.ProgressBar(len(results))\n","    _mAPs = {}\n","    for i, (result, ) in enumerate(zip(results)):\n","        # self.dataset[i] should not call directly\n","        # because there is a risk of mismatch\n","        data_info = dataset.prepare_train_img(i)\n","        mAP = eval_fn(result, data_info['ann_info'])\n","        _mAPs[i] = mAP\n","        prog_bar.update()\n","\n","    # descending select topk image\n","    _mAPs = list(sorted(_mAPs.items(), key=lambda kv: kv[1]))\n","    good_mAPs = _mAPs[-topk:]\n","    bad_mAPs = _mAPs[:topk]\n","\n","    good_dir = osp.abspath(osp.join(show_dir, 'good'))\n","    bad_dir = osp.abspath(osp.join(show_dir, 'bad'))\n","    #self._save_image_gts_results(dataset, results, good_mAPs, good_dir)\n","    #self._save_image_gts_results(dataset, results, bad_mAPs, bad_dir)\n","\n","def bbox_map_eval(det_result, annotation):\n","    \"\"\"Evaluate mAP of single image det result.\n","    Args:\n","        det_result (list[list]): [[cls1_det, cls2_det, ...], ...].\n","            The outer list indicates images, and the inner list indicates\n","            per-class detected bboxes.\n","        annotation (dict): Ground truth annotations where keys of\n","             annotations are:\n","            - bboxes: numpy array of shape (n, 4)\n","            - labels: numpy array of shape (n, )\n","            - bboxes_ignore (optional): numpy array of shape (k, 4)\n","            - labels_ignore (optional): numpy array of shape (k, )\n","    Returns:\n","        float: mAP\n","    \"\"\"\n","\n","    # use only bbox det result\n","    if isinstance(det_result, tuple):\n","        bbox_det_result = [det_result[0]]\n","    else:\n","        bbox_det_result = [det_result]\n","    # mAP\n","    iou_thrs = np.linspace(\n","        .5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n","    mean_aps = []\n","    for thr in iou_thrs:\n","        mean_ap, _ = eval_map(\n","            bbox_det_result, [annotation], iou_thr=thr, logger='silent')\n","        mean_aps.append(mean_ap)\n","    return sum(mean_aps) / len(mean_aps)\n","\n","\n","def show_det_image(pkl, annot_dict, img, j):\n","        pkl_bboxes = np.concatenate((pkl[j][0],pkl[j][1],pkl[j][2]))\n","        pkl_labels = pkl_labels_fuc(pkl, j)\n","\n","        imshow_det_bboxes(img,\n","                          pkl_bboxes,\n","                          pkl_labels,\n","                          segms=None,\n","                          class_names=[\"shsy5y\", \"cort\", \"astro\"],\n","                          score_thr=0.2,\n","                          show=True)\n","        \n","def DET_INFER(out, json_file, config, checkpoint, show, eval, data_annot_file_dir, data_test_dir):\n","        args = {\n","            \"out\": out,\n","            \"json_file\": json_file,\n","            \"config\": config,\n","            \"eval\": eval,\n","            \"checkpoint\": checkpoint,\n","            \"show\": show\n","        }\n","\n","        print(args[\"config\"])\n","\n","        cfg = Config.fromfile(args[\"config\"])\n","\n","        cfg.data.test.ann_file = data_annot_file_dir\n","        cfg.data.test.img_prefix =  data_test_dir #\"/kaggle/input/sartorius-cell-instance-segmentation/test/\"  ## train?\n","        \n","        if \"pretrained\" in cfg.model:\n","            cfg.model.pretrained = None\n","        if cfg.model.get(\"neck\"):\n","            if isinstance(cfg.model.neck, list):\n","                for neck_cfg in cfg.model.neck:\n","                    if neck_cfg.get(\"rfp_backbone\"):\n","                        if neck_cfg.rfp_backbone.get(\"pretrained\"):\n","                            neck_cfg.rfp_backbone.pretrained = None\n","            elif cfg.model.neck.get(\"rfp_backbone\"):\n","                if cfg.model.neck.rfp_backbone.get(\"pretrained\"):\n","                    cfg.model.neck.rfp_backbone.pretrained = None\n","\n","        # in case the test dataset is concatenated\n","        samples_per_gpu = 1\n","        if isinstance(cfg.data.test, dict):\n","            cfg.data.test.test_mode = True\n","            samples_per_gpu = cfg.data.test.pop(\"samples_per_gpu\", 1)\n","            if samples_per_gpu > 1:\n","                # Replace 'ImageToTensor' to 'DefaultFormatBundle'\n","                cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n","        elif isinstance(cfg.data.test, list):\n","            for ds_cfg in cfg.data.test:\n","                ds_cfg.test_mode = True\n","            samples_per_gpu = max(\n","                [ds_cfg.pop(\"samples_per_gpu\", 1) for ds_cfg in cfg.data.test]\n","            )\n","            if samples_per_gpu > 1:\n","                for ds_cfg in cfg.data.test:\n","                    ds_cfg.pipeline = replace_ImageToTensor(ds_cfg.pipeline)\n","\n","        distributed = False\n","\n","\n","        cfg = patch_config(cfg)\n","        # build the dataloader\n","        dataset = build_dataset(cfg.data.test)\n","        data_loader = build_dataloader(\n","            dataset,\n","            samples_per_gpu=samples_per_gpu,\n","            workers_per_gpu=cfg.data.workers_per_gpu,\n","            dist=distributed,\n","            shuffle=False,\n","        )\n","\n","        # build the model and load checkpoint\n","        cfg.model.train_cfg = None\n","        model = build_detector(cfg.model, test_cfg=cfg.get(\"test_cfg\"))\n","        fp16_cfg = cfg.get(\"fp16\", None)\n","        if fp16_cfg is not None:\n","            wrap_fp16_model(model)\n","        checkpoint = load_checkpoint(model, args[\"checkpoint\"], map_location=\"cpu\")\n","\n","        # old versions did not save class info in checkpoints, this walkaround is\n","        # for backward compatibility\n","        if \"CLASSES\" in checkpoint.get(\"meta\", {}):\n","            model.CLASSES = checkpoint[\"meta\"][\"CLASSES\"]\n","        else:\n","            model.CLASSES = dataset.CLASSES\n","\n","        if not distributed:\n","            model = MMDataParallel(model, device_ids=[0])\n","            outputs = single_gpu_test(\n","                model, data_loader, args[\"show\"] #, args[\"show\"]_dir, args_seg[\"show\"]_score_thr\n","            )\n","\n","\n","        print(f\"\\nwriting results to output_dir\")\n","        mmcv.dump(outputs, args[\"out\"])\n","        kwargs = {}\n","\n","        eval_kwargs = cfg.get(\"evaluation\", {}).copy()\n","        # hard-code way to remove EvalHook args\n","        for key in [\n","            \"type\",\n","            \"interval\",\n","            \"tmpdir\",\n","            \"start\",\n","            \"gpu_collect\",\n","            \"save_best\",\n","            \"rule\",\n","        ]:\n","            eval_kwargs.pop(key, None)\n","        eval_kwargs.update(dict(metric=args[\"eval\"], **kwargs))\n","        #metric = dataset.evaluate(outputs, **eval_kwargs)\n","        #print(metric)\n","        #metric_dict = dict(config=args[\"config\"], metric=metric)\n","        #mmcv.dump(metric_dict, args[\"json_file\"])\n","\n","def SEG_INFER(out, json_file, config, checkpoint, pred_file_path, eval, data_annot_file_dir, data_test_dir):\n","\n","        args_seg = {\n","          \"out\": out, \n","          \"json_file\": json_file,\n","          \"config\": config,\n","          \"eval\": eval, \n","          \"checkpoint\": checkpoint,\n","          \"pred_file_path\": pred_file_path \n","        }\n","\n","        cfg = mmcv.Config.fromfile(args_seg[\"config\"])\n","\n","\n","\n","        ############\n","        cfg.model.pretrained = None\n","        cfg.data.test.test_mode = True\n","        distributed = False\n","\n","        cfg.data.test.pred_file = pred_file_path\n","        cfg.data.test.ann_file = data_annot_file_dir\n","        cfg.data.test.img_dir = data_test_dir\n","        cfg.data.test.helper_dataset.ann_file = data_annot_file_dir\n","        cfg.data.test.helper_dataset.img_prefix = data_test_dir\n","        #########\n","\n","        # build the dataloader\n","        # TODO: support multiple images per gpu (only minor changes are needed)\n","        dataset = build_dataset(cfg.data.test)\n","        data_loader = build_dataloader(\n","            dataset,\n","            samples_per_gpu=1,\n","            workers_per_gpu=cfg.data.workers_per_gpu,\n","            dist=distributed,\n","            shuffle=False)\n","\n","        # build the model and load checkpoint\n","        cfg.model.train_cfg = None\n","        model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n","        fp16_cfg = cfg.get('fp16', None)\n","        if fp16_cfg is not None:\n","            wrap_fp16_model(model)\n","        if args_seg[\"checkpoint\"] != 'none':\n","            checkpoint = load_checkpoint(model, args_seg[\"checkpoint\"], map_location='cpu')\n","        else:\n","            checkpoint = dict()\n","        if 'CLASSES' in checkpoint.get('meta', {}):\n","            model.CLASSES = checkpoint['meta']['CLASSES']\n","        else:\n","            print('\"CLASSES\" not found in meta, use dataset.CLASSES instead')\n","            model.CLASSES = dataset.CLASSES\n","        if 'PALETTE' in checkpoint.get('meta', {}):\n","            model.PALETTE = checkpoint['meta']['PALETTE']\n","        else:\n","            print('\"PALETTE\" not found in meta, use dataset.PALETTE instead')\n","            model.PALETTE = dataset.PALETTE\n","\n","        # clean gpu memory when starting a new evaluation.\n","        torch.cuda.empty_cache()\n","        eval_kwargs = {}\n","\n","        efficient_test = eval_kwargs.get('efficient_test', False)\n","        if efficient_test:\n","            warnings.warn(\n","                '``efficient_test=True`` does not have effect in tools/test.py, '\n","                'the evaluation and format results are CPU memory efficient by '\n","                'default')\n","\n","        tmpdir = None\n","        if not distributed:\n","            model = MMDataParallel(model, device_ids=[0])\n","            results = single_gpu_test(\n","                model,\n","                data_loader, \n","                0, #args_seg[\"show\"],\n","                0, #args_seg[\"show_dir\"],\n","                False,\n","                0.5, #args_seg[\"opacity\"],\n","                pre_eval=True,\n","                format_only=False,\n","                format_args=eval_kwargs\n","                )\n","\n","\n","\n","\n","        warnings.warn(\n","            'The behavior of ``args_seg[\"out\"]`` has been changed since MMSeg '\n","            'v0.16, the pickled outputs could be seg map as type of '\n","            'np.array, pre-eval results or file paths for '\n","            '``dataset.format_results()``.')\n","        print(f'\\nwriting results to {args_seg[\"out\"]}')\n","        mmcv.dump(results, args_seg[\"out\"])\n","        eval_kwargs.update(metric=args_seg[\"eval\"])\n","        #metric = dataset.evaluate(results, **eval_kwargs)\n","        #metric_dict = dict(config=args_seg[\"config\"], metric=metric)\n","        #mmcv.dump(metric_dict, args_seg[\"json_file\"], indent=4)\n","        \n","\n","        mmdet_style_results = dataset.prepare_mmdet_style_results(results, **eval_kwargs)\n","        \n","        print(f'\\nwriting results to: /kaggle/working/mmdet_style_results.pkl')\n","        mmcv.dump(mmdet_style_results, \"/kaggle/working/mmdet_style_results.pkl\")\n","        return mmdet_style_results"]},{"cell_type":"markdown","metadata":{"id":"hFIJzmoAfksb"},"source":["# Defining Directories:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RFrt3gV5fpR0"},"outputs":[],"source":["####################################\n","# Defining Directories:\n","os.chdir(main_dir)\n","data_dir = \"/content/drive/MyDrive/Deep_Learning_Itay_Sagi/Project/Sartorius_Cell_Instance_Segmentation/data/\"  #'./data/'\n","data_test_dir =  data_dir + 'train/' #'test/' \n","data_annot_file_dir =  data_dir + \"sartorius_coco_val_95_5.json\" #\"test_annot.json\"     \n","\n","output_dir_det = './output_and_results/det/'\n","output_dir_seg = './output_and_results/seg/' \n","show_dir_seg =  './output_and_results/seg/results_images/'"]},{"cell_type":"markdown","metadata":{"id":"-Wfpotfp5990"},"source":["# Experiment Conifg and Output files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Is81JF8VKlAR"},"outputs":[],"source":["###############################\n","exp_num = '01'\n","###############################\n","# DETECTION\n","det_ckpt_1_path = './models/det/det1_cascade_rcnn_resnext/final_weights/final_weights_det1_cascade_rcnn_resnext.pth'\n","det_ckpt_2_path = './models/det/det2_cascade_rcnn_resnest/final_weights/final_weights_det2_cascade_rcnn_resnest.pth'\n","det_ckpt_3_path = './models/det/det3_faster_rcnn_swin/final_weights/final_weights_det3_faster_rcnn_swin.pth'\n","det_ckpt_4_path = './models/det/det4_softteacher_faster_rcnn_resnext/final_weights/final_weights_det4_softteacher_faster_rcnn_resnext.pth'\n","\n","det_config_1_path = './models/det/det1_cascade_rcnn_resnext/configs/config_det1_cascade_rcnn_resnext.py'\n","det_config_2_path = './models/det/det2_cascade_rcnn_resnest/configs/config_det2_cascade_rcnn_resnest.py'\n","det_config_3_path = './models/det/det3_faster_rcnn_swin/configs/config_det3_faster_rcnn_swin.py'\n","det_config_4_path = './models/det/det4_softteacher_faster_rcnn_resnext/configs/config_det4_softteacher_faster_rcnn_resnext.py'\n","\n","\n","\n","# Output file names\n","det_pkl_1      = output_dir_det + 'det_results_test_1_' + exp_num + '.pkl'    \n","det_json_1     = output_dir_det + 'det_results_test_1_' + exp_num + '.json'  \n","\n","det_pkl_2      = output_dir_det + 'det_results_test_2_' + exp_num + '.pkl'   \n","det_json_2     = output_dir_det + 'det_results_test_2_' + exp_num + '.json'  \n","\n","det_pkl_3      = output_dir_det + 'det_results_test_3_' + exp_num + '.pkl'    \n","det_json_3     = output_dir_det + 'det_results_test_3_' + exp_num + '.json'\n","\n","det_pkl_4      = output_dir_det + 'det_results_test_4_' + exp_num + '.pkl'    \n","det_json_4     = output_dir_det + 'det_results_test_4_' + exp_num + '.json'\n","###############################\n","# WBF\n","# Params:\n","img_scale = [520,704]\n","iou_thr = 0.6\n","skip_box_thr = 0.001\n","# sigma = 0.1\n","weights = [3,3,2,1] \n","\n","# Output file name:\n","wbf_filename = 'wbf_' + exp_num + '.pkl'\n","wbf_output_file_path = output_dir_det  + wbf_filename  \n","\n","\n","\n","###############################\n","# SEGMENTATION\n","seg_ckpt_path = './models/seg/seg_upernet_swin/final_weights/final_weights_seg_upernet_swin.pth'  \n","seg_config_path = './models/seg/seg_upernet_swin/configs/config_seg_upernet_swin.py'\n","\n","# Output file names\n","seg_pkl = output_dir_seg + 'seg_results_test' + exp_num + '.pkl'   \n","seg_json = output_dir_seg + 'seg_results_test' + exp_num + '.json' "]},{"cell_type":"markdown","metadata":{"id":"IvQpqAY_gYc0"},"source":["# Create Annotation File (for test folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"79WoKndzgX47"},"outputs":[],"source":["import json\n","def coco_structure_annot_file(data_test_dir):\n","\n","    ## categories:\n","    cats =  [{\"id\": 1, \"name\": \"shsy5y\", \"supercategory\": \"none\"}, {\"id\": 2, \"name\": \"cort\", \"supercategory\": \"none\"}, {\"id\": 3, \"name\": \"astro\", \"supercategory\": \"none\"}]\n","\n","    ## images:\n","    width = 704\n","    height = 520\n","    files = os.listdir(data_test_dir)\n","    labels = ['shsy5y', 'astro', 'cort']\n","\n","    id_c=0\n","    images=[]\n","    for file in files:\n","          image_path = os.path.join(data_test_dir, file)\n","          label = file.split(\"[\")[0]\n","          if label == 'astros': \n","              label = 'astro'\n","          images.append({'id':id_c, 'width':width, 'height':height, 'file_name':image_path})\n","          id_c+=1\n","        \n","    return {'categories':cats, 'images':images}\n","\n","'''\n","# Converting dataset dataframe to COCO structure\n","data_root = coco_structure_annot_file(data_test_dir)\n","\n","# Saving COCO structure dataset in json file\n","data_annot_file = open(data_annot_file_dir, \"w\", encoding='utf-8')\n","json.dump(data_root, data_annot_file, ensure_ascii=True, indent=4)\n","data_annot_file.close()'''"]},{"cell_type":"markdown","metadata":{"id":"ekPvBfMY3npF"},"source":["# DET Inference - Model 1 (cascade_rcnn_resnext)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01kwLIbuK4Xh"},"outputs":[],"source":["print(f\"det_pkl_1: {det_pkl_1}\")\n","print(f\"det_json_1: {det_json_1}\")\n","print(f\"det_config_1_path: {det_config_1_path}\")\n","print(f\"det_ckpt_1_path: {det_ckpt_1_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lWGxzO5p3wmJ"},"outputs":[],"source":["import argparse\n","import os\n","import os.path as osp\n","import time\n","import warnings\n","\n","import mmcv\n","import torch\n","from mmcv import Config, DictAction\n","from mmcv.cnn import fuse_conv_bn\n","from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n","from mmcv.runner import get_dist_info, init_dist, load_checkpoint, wrap_fp16_model\n","from mmdet.apis import multi_gpu_test, single_gpu_test\n","from mmdet.datasets import build_dataloader, build_dataset, replace_ImageToTensor\n","from mmdet.models import build_detector\n","\n","from ssod.utils import patch_config \n","\n","\n","\n","DET_INFER(det_pkl_1, det_json_1, det_config_1_path, det_ckpt_1_path, 1, \"bbox\", data_annot_file_dir, data_test_dir)"]},{"cell_type":"markdown","metadata":{"id":"MDhYwcvENdq1"},"source":["# DET Inference - Model 2 (cascade_rcnn_resnest)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hw39PbotNccf"},"outputs":[],"source":["DET_INFER(det_pkl_2, det_json_2, det_config_2_path, det_ckpt_2_path, 1, \"bbox\", data_annot_file_dir, data_test_dir)"]},{"cell_type":"markdown","metadata":{"id":"IOZmom0ipktW"},"source":["# DET Inference - Model 3 (faster_rcnn_swin)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dxI6vr-2pyY6"},"outputs":[],"source":["DET_INFER(det_pkl_3, det_json_3, det_config_3_path, det_ckpt_3_path, 1, \"bbox\", data_annot_file_dir, data_test_dir)"]},{"cell_type":"markdown","metadata":{"id":"sg5prt1Pplt8"},"source":["# DET Inference - Model 4 (softteacher_faster_rcnn_resnext)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owOehGODp0wr"},"outputs":[],"source":["DET_INFER(det_pkl_4, det_json_4, det_config_4_path, det_ckpt_4_path, 1, \"bbox\", data_annot_file_dir, data_test_dir)"]},{"cell_type":"markdown","metadata":{"id":"d0OBzIE-1GDx"},"source":["# WBF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaA4VKEAW7z1"},"outputs":[],"source":["with open(det_pkl_1, 'rb') as f:\n","    bbox_model1 = pickle.load(f)\n","with open(det_pkl_2, 'rb') as f:\n","    bbox_model2 = pickle.load(f)\n","with open(det_pkl_3, 'rb') as f:\n","    bbox_model3 = pickle.load(f)\n","with open(det_pkl_4, 'rb') as f:\n","    bbox_model4 = pickle.load(f)\n","\n","\n","bbox_models = [bbox_model1,bbox_model2,bbox_model3,bbox_model4]\n","\n","merged_bbox_wbf = wbf_si(bbox_models,img_scale,weights,iou_thr,skip_box_thr) \n","\n","pickle.dump(merged_bbox_wbf, open(wbf_output_file_path, 'wb'))"]},{"cell_type":"markdown","metadata":{"id":"klQbe7a2of8h"},"source":["# SEG Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qM7IqAtPUDF6"},"outputs":[],"source":["pred_file_path = wbf_output_file_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmXisabVQ4ag"},"outputs":[],"source":["print(f\"seg_pkl: {seg_pkl}\")\n","print(f\"seg_json: {seg_json}\")\n","print(f\"seg_config_path: {seg_config_path}\")\n","print(f\"seg_ckpt_path: {seg_ckpt_path}\")\n","print(f\"pred_file_path: {pred_file_path}\")\n","print(f\"data_annot_file_dir: {data_annot_file_dir}\")\n","print(f\"data_test_dir: {data_test_dir}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoDQX0gCbsRE"},"outputs":[],"source":["from mmcv.utils import DictAction\n","from mmseg.apis import multi_gpu_test, single_gpu_test\n","from mmseg.datasets import build_dataloader, build_dataset\n","from mmseg.models import build_segmentor\n","\n","mmdet_style_results = SEG_INFER(seg_pkl, seg_json, seg_config_path, seg_ckpt_path, pred_file_path, \"dummy\", data_annot_file_dir, data_test_dir)"]},{"cell_type":"markdown","metadata":{"id":"y8nogzLhwrCm"},"source":["-------------------------------- Kaggle Inference: ---------------------------------------"]},{"cell_type":"markdown","metadata":{"id":"KwgOz34zw0tW"},"source":["# Kaggle - Importations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQOGXI_Vw1Yy"},"outputs":[],"source":["#############\n","# Importations\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy.random\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import sklearn\n","import torchvision\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import PIL\n","from PIL import Image, ImageEnhance\n","import albumentations as A\n","import albumentations \n","from albumentations.pytorch import ToTensorV2\n","\n","import glob\n","from pathlib import Path\n","import pycocotools\n","from pycocotools import mask\n","import re\n","\n","from mmdet.apis import train_detector\n","from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n","\n","\n","#!pip install cupy\n","#import cupy as cp\n","import gc\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"oGqzz1EBxAWY"},"source":["# Kaggle - Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k1vVh_nYw_xi"},"outputs":[],"source":["IMG_WIDTH = 704\n","IMG_HEIGHT = 520\n","\n","def rle_decode(mask_rle, shape):\n","    '''\n","    mask_rle: run-length as string formated (start length)\n","    shape: (height,width) of array to return \n","    Returns numpy array, 1 - mask, 0 - background\n","\n","    '''\n","    s = mask_rle.split()\n","    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n","    starts -= 1\n","    ends = starts + lengths\n","    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n","    for lo, hi in zip(starts, ends):\n","        img[lo:hi] = 1\n","    return img.reshape(shape)\n","\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","def rle_encoding(x):\n","    dots = np.where(x.flatten() == 1)[0]\n","    run_lengths = []\n","    prev = -2\n","    for b in dots:\n","        if (b>prev+1): run_lengths.extend((b + 1, 0))\n","        run_lengths[-1] += 1\n","        prev = b\n","    return ' '.join(map(str, run_lengths))\n","\n","'''def get_mask_from_result(result):\n","    d = {True : 1, False : 0}\n","    u,inv = np.unique(result,return_inverse = True)\n","    mk = cp.array([d[x] for x in u])[inv].reshape(result.shape)\n","#     print(mk.shape)\n","    return mk'''\n","\n","def does_overlap(mask, other_masks):\n","    for other_mask in other_masks:\n","        if np.sum(np.logical_and(mask, other_mask)) > 0:\n","            return True\n","    return False\n","\n","\n","def remove_overlapping_pixels(mask, other_masks):\n","    for other_mask in other_masks:\n","        if np.sum(np.logical_and(mask, other_mask)) > 0:\n","            print(\"Overlap detected\")\n","            mask[np.logical_and(mask, other_mask)] = 0\n","    return mask\n","\n","def get_img_and_mask(img_path, annotation, width, height):\n","    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n","    img_mask = np.zeros((height, width), dtype=np.uint8)\n","    for i, annot in enumerate(annotation): \n","        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n","    img = cv2.imread(img_path)[..., ::-1]\n","    return img[..., 0], img_mask\n","\n","def plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n","    \"\"\" Function to take an image and the corresponding mask and plot\n","    \n","    Args:\n","        img (np.arr): 1 channel np arr representing the image of cellular structures\n","        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n","        invert_img (bool, optional): Whether or not to invert the base image\n","        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n","        \n","    Returns:\n","        None; Plots the two arrays and overlays them to create a merged image\n","    \"\"\"\n","    plt.figure(figsize=(20,10))\n","    \n","    plt.subplot(1,3,1)\n","    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n","    \n","    # Flip black-->white ... white-->black\n","    if invert_img:\n","        _img = _img.max()-_img\n","        \n","    if boost_contrast:\n","        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n","        \n","    plt.imshow(_img)\n","    plt.axis(False)\n","    plt.title(\"Cell Image\", fontweight=\"bold\")\n","    \n","    plt.subplot(1,3,2)\n","    _mask = np.zeros_like(_img)\n","    _mask[..., 0] = mask\n","    plt.imshow(mask, cmap='rainbow')\n","    plt.axis(False)\n","    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n","    \n","    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n","    plt.subplot(1,3,3)\n","    plt.imshow(merged)\n","    plt.axis(False)\n","    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n","    \n","    plt.tight_layout()\n","    plt.show()\n","    \n","def pkl_labels_func_kaggle(pkl, j):\n","    class0_n=len(pkl[j][0][0])\n","    class1_n=len(pkl[j][0][1])\n","    class2_n=len(pkl[j][0][2])\n","    pkl_labels=[]\n","    for i in range(class0_n):\n","        pkl_labels.append(0)\n","    for i in range(class1_n):\n","        pkl_labels.append(1)\n","    for i in range(class2_n):\n","        pkl_labels.append(2)\n","    \n","    return np.asarray(pkl_labels)"]},{"cell_type":"markdown","metadata":{"id":"_zA3L89cxJYJ"},"source":["# Kaggle - Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYonb99Aw6s4"},"outputs":[],"source":["confidence_thresholds = {0: 0.25, 1: 0.55, 2: 0.35} #[\"shsy5y\", \"cort\", \"astro\"],\n","segms = []\n","files = []\n","\n","\n","import copy\n","from mmdet.core.visualization import imshow_det_bboxes\n","\n","mmdet_style_results_forplot = copy.deepcopy(mmdet_style_results)\n","\n","for j, image in enumerate(data_root['images']):\n","\n","    img = mmcv.imread(image['file_name'])\n","    idx_del_bbox = []\n","    idx_del_labels = []\n","    pkl_bboxes = np.concatenate((mmdet_style_results[j][0][0],mmdet_style_results[j][0][1],mmdet_style_results[j][0][2])).tolist()\n","    pkl_labels = pkl_labels_func_kaggle(mmdet_style_results, j).tolist()\n","\n","    previous_masks = []\n","    previous_masks_for_plot = []\n","    num_of_thresholded=0\n","    m=0\n","    for i, classe in enumerate(mmdet_style_results[j][0]):\n","        if len(classe) != (0, 5):\n","            bbs = classe\n","            sgs = mmdet_style_results[j][1][i]\n","            k=0\n","            for bb, sg in zip(bbs,sgs):\n","                box = bb[:4]\n","                cnf = bb[4]\n","\n","                if cnf >= confidence_thresholds[i]:\n","                    mask = pycocotools.coco.maskUtils.decode(sg) \n","                    mask = remove_overlapping_pixels(mask, previous_masks)\n","                    previous_masks_for_plot.append(np.array(mask, dtype=bool)) \n","                    previous_masks.append(mask)\n","                else:\n","                    num_of_thresholded+=1\n","                    idx_del_bbox.append(m)\n","                    idx_del_labels.append(m)\n","                m+=1\n","    \n","    for i in reversed(idx_del_bbox):\n","        del pkl_bboxes[i]\n","    \n","    for i in reversed(idx_del_labels):\n","        del pkl_labels[i]\n","\n","    print(np.asarray(previous_masks_for_plot).shape)\n","    print(np.asarray(pkl_bboxes).shape)\n","    print(np.asarray(pkl_labels).shape)\n","    print(num_of_thresholded)\n","    imshow_det_bboxes(img,\n","                      np.asarray(pkl_bboxes),\n","                      np.asarray(pkl_labels),\n","                      segms=np.asarray(previous_masks_for_plot),\n","                      class_names=[\"shsy5y\", \"cort\", \"astro\"],\n","                      score_thr=0,\n","                      show=True)\n","    \n","    for mk in previous_masks:\n","            rle_mask = rle_encoding(mk)\n","            segms.append(rle_mask)\n","            files.append(image['file_name'].split('/')[-1].split('.')[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtNg3FZJLRSI"},"outputs":[],"source":["indexes = []\n","for i, segm in enumerate(segms):\n","    if segm == '':\n","        indexes.append(i)\n","        \n","for element in sorted(indexes, reverse = True):\n","    del segms[element]\n","    del files[element]\n","    \n","files = pd.Series(files, name='id')\n","preds = pd.Series(segms, name='predicted')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEkixMYFqXWx"},"outputs":[],"source":["preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GwetGvRqYWa"},"outputs":[],"source":["submission_df = pd.concat([files, preds], axis=1)\n","submission_df.to_csv('./output_and_results/submission.csv', index=False)\n","submission_df"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"inference_det_and_seg.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}